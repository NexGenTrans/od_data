{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore') \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import math\n",
    "import requests\n",
    "import sys,pytz\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import time\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "#!pip install elasticsearch==7.13.0\n",
    "#!pip install elasticsearch-dsl==7.4.0\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environmental variables\n",
    "env=os.environ\n",
    "DB_USERNAME =  env.get('AURORA_USER','')\n",
    "DB_PASSWORD = env.get('AURORA_PW','')\n",
    "AURORA_HOST = env.get('AURORA_HOST','analytics-prod.cluster-cq8upvxokils.us-west-2.rds.amazonaws.com')\n",
    "AURORA_DB_NAME = env.get('AURORA_DB_NAME','analytics')\n",
    "\n",
    "RS_HOST = env.get('RS_HOST', 'redshift-cluster-1.cgktzu6aypqt.us-west-2.redshift.amazonaws.com')\n",
    "RS_USERNAME = env.get('RS_USERNAME', 'awsuser')\n",
    "RS_PASSWORD = env.get('RS_PASSWORD', 'mAjYP7x90g4^')\n",
    "RS_DB_NAME = env.get('RS_DB_NAME','avl')\n",
    "DB_ADRESS = '%s/%s' % (AURORA_HOST, AURORA_DB_NAME)\n",
    "UPDATE_DATA_ORDER_GROUP = env.get('UPDATE_DATA_ORDER_GROUP','')\n",
    "\n",
    "ES_API_KEY =  env.get('ES_API_KEY','')\n",
    "ES_API_ID = env.get('ES_API_ID','')\n",
    "ES_CLUSTER_ID = env.get('ES_CLUSTER_ID','')\n",
    "\n",
    "try:\n",
    "    __IPYTHON__\n",
    "    inIPython = True\n",
    "except NameError:\n",
    "    inIPython = False\n",
    "    \n",
    "if inIPython == True:\n",
    "    dftemp = pd.read_csv('../web-variables.env', header=None, names=['vars'])\n",
    "    for i,idat in dftemp.iterrows():\n",
    "        key, value = idat[0].split('=',1)\n",
    "        os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from pathlib import Path\n",
    "\n",
    "# dotenv_path = Path('/Users/saberabdoli/Documents/reports_dev/web-variables.env')\n",
    "# load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# DB_USERNAME =  env.get('AURORA_USER','')\n",
    "# DB_PASSWORD = env.get('AURORA_PW','')\n",
    "# AURORA_HOST = env.get('AURORA_HOST','analytics-prod.cluster-cq8upvxokils.us-west-2.rds.amazonaws.com')\n",
    "# AURORA_DB_NAME = env.get('AURORA_DB_NAME','analytics')\n",
    "\n",
    "# RS_HOST = env.get('RS_HOST', '')\n",
    "# RS_USERNAME = env.get('RS_USERNAME', '')\n",
    "# RS_PASSWORD = env.get('RS_PASSWORD', '')\n",
    "# RS_DB_NAME = env.get('RS_DB_NAME','avl')\n",
    "# DB_ADRESS = '%s/%s' % (AURORA_HOST, AURORA_DB_NAME)\n",
    "# UPDATE_DATA_ORDER_GROUP = env.get('UPDATE_DATA_ORDER_GROUP','')\n",
    "\n",
    "# ES_API_KEY =  env.get('ES_API_KEY','')\n",
    "# ES_API_ID = env.get('ES_API_ID','')\n",
    "# ES_CLUSTER_ID = env.get('ES_CLUSTER_ID','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format=\\\n",
    "        '%(asctime)s %(levelname)s -- %(processName)s %(filename)s:%(lineno)s -- %(message)s', level=logging.INFO)\n",
    "\n",
    "#set up logging\n",
    "LOGGING_CONFIG = {\n",
    "    'version': 1, # required\n",
    "    'disable_existing_loggers': True, # this config overrides all other loggers\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '%(asctime)s %(levelname)s -- %(message)s'\n",
    "        },\n",
    "        'whenAndWhere': {\n",
    "            'format': '%(asctime)s %(levelname)s -- %(processName)s %(filename)s:%(lineno)s -- %(message)s'\n",
    "        }\n",
    "    },\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'level': 'DEBUG',\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'formatter': 'whenAndWhere'\n",
    "        }\n",
    "    },\n",
    "    'loggers': {\n",
    "        '': {\n",
    "            'level': 'INFO',\n",
    "            'handlers': ['console']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# logging.config.dictConfig(LOGGING_CONFIG)\n",
    "log = logging.getLogger('')\n",
    "log.setLevel(env.get('LOG_LEVEL', 'DEBUG'))\n",
    "\n",
    "es_logger = logging.getLogger('elasticsearch')\n",
    "es_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://awsuser:mAjYP7x90g4^@redshift-cluster-1.cgktzu6aypqt.us-west-2.redshift.amazonaws.com:5439/dev'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create db connection string\n",
    "#con_str = r'mysql://{}:{}@{}'.format(DB_USERNAME, DB_PASSWORD, DB_ADRESS)\n",
    "con_str = r'postgresql://{}:{}@{}:5439/dev'.format(RS_USERNAME, RS_PASSWORD, RS_HOST)\n",
    "con_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging as log\n",
    "# import os\n",
    "# logname = 'logs_es_avl_data_pipeline.csv'\n",
    "# log.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "# log.basicConfig(filename=logname,\n",
    "#                     filemode='a', \n",
    "#                     datefmt='%H:%M:%S', \n",
    "#                     format='%(asctime)s %(levelname)s -- %(processName)s %(filename)s:%(lineno)s -- %(message)s', \n",
    "#                     level=log.INFO)\n",
    "# log.info('Current working directory is: %s'%os.getcwd())\n",
    "# log.info('Connection to db is: %s'%con_str)\n",
    "# log.info('Connection to RS_USERNAME is: %s'%RS_USERNAME)\n",
    "# log.info('Connection to RS_PASSWORD is: %s'%RS_PASSWORD)\n",
    "# log.info('Connection to RS_HOST is: %s'%RS_HOST)\n",
    "# log.info('Connection to Elasticsearch is: %s'%es)\n",
    "# log.info('Connection to ES_API_ID is: %s'%ES_API_ID)\n",
    "# log.info('Connection to ES_API_KEY is: %s'%ES_API_KEY)\n",
    "# log.info('Connection to ES_CLUSTER_ID is: %s'%ES_CLUSTER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_csv_files(path):\n",
    "    \n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    csv_files = []\n",
    "\n",
    "    # Walk through all the directories and subdirectories in the given path\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Find all the csv files in the current directory\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                # Add the full path of the csv file to the list\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Print the list of csv files\n",
    "    #print(csv_files)\n",
    "    \n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_od_data_to_rs(df):\n",
    "   \n",
    "    # connect to MSSQL server,\n",
    "    engine = create_engine(con_str)\n",
    "    # connect to the database,\n",
    "    connection = engine.connect()\n",
    "\n",
    "    # start time,\n",
    "    start_time = time.time()\n",
    "\n",
    "    df['OriginOID'] = df['OriginOID'].astype('int')\n",
    "    df['DestinationOID'] = df['DestinationOID'].astype('int')\n",
    "    df['DestinationRank'] = df['DestinationRank'].astype('int')\n",
    "    df['Total_Time'] = df['Total_Time'].astype('Float64')\n",
    "    df['Total_Distance'] = df['Total_Distance'].astype('Float64') \n",
    "\n",
    "    #sort columns alphabetically and upload\n",
    "    df = df[['OriginOID', 'DestinationOID', 'DestinationRank', 'Total_Time', 'Total_Distance']].sort_index(axis = 1)\n",
    "\n",
    "    df.to_sql(con=con_str, name='census_tracts_centroids_od_results', schema='trucking_times',\n",
    "              if_exists='append', index=False, chunksize=10000)\n",
    "\n",
    "    connection.close()\n",
    "    log.info('All %s new records are inserted in %s seconds' % (len(df), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_attempt_export_od_data_to_rs(df): \n",
    "    \n",
    "    # define the number of retry attempts\n",
    "    NUM_RETRIES = 3\n",
    "\n",
    "    # attempt to push the data to the database\n",
    "    for i in range(NUM_RETRIES):\n",
    "        try:\n",
    "            # export data to the database\n",
    "            export_od_data_to_rs(df)\n",
    "\n",
    "            # exit the loop if the data was successfully pushed to the database\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            # print the exception message\n",
    "            print(\"An exception occurred:\", str(e))\n",
    "\n",
    "            # wait for 1 second before retrying\n",
    "            time.sleep(5)\n",
    "\n",
    "    # close the database connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\Users\\analytics\\Documents\\od_results\"\n",
    "csv_files = read_all_csv_files(path)\n",
    "len(csv_files), csv_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    print(csv_file)\n",
    "    df=pd.read_csv(csv_files[0])\n",
    "    print(len(df))\n",
    "    multiple_attempt_export_od_data_to_rs(df)\n",
    "    print('*'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_od_data_to_rs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, csv_file in enumerate(csv_files):\n",
    "    print(i/len(csv_files), csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3849"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginOID</th>\n",
       "      <th>DestinationOID</th>\n",
       "      <th>DestinationRank</th>\n",
       "      <th>Total_Time</th>\n",
       "      <th>Total_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>10242</td>\n",
       "      <td>2</td>\n",
       "      <td>5.808119</td>\n",
       "      <td>2.092222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>10243</td>\n",
       "      <td>3</td>\n",
       "      <td>6.637652</td>\n",
       "      <td>3.220984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>10227</td>\n",
       "      <td>4</td>\n",
       "      <td>152.399386</td>\n",
       "      <td>132.892823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>10226</td>\n",
       "      <td>5</td>\n",
       "      <td>155.548170</td>\n",
       "      <td>134.106320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OriginOID  DestinationOID  DestinationRank  Total_Time  Total_Distance\n",
       "0      10001           10001                1    0.000000        0.000000\n",
       "1      10001           10242                2    5.808119        2.092222\n",
       "2      10001           10243                3    6.637652        3.220984\n",
       "3      10001           10227                4  152.399386      132.892823\n",
       "4      10001           10226                5  155.548170      134.106320"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(csv_files[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OriginOID', 'DestinationOID', 'DestinationRank', 'Total_Time',\n",
       "       'Total_Distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MSSQL server,\n",
    "engine = create_engine(con_str)\n",
    "# connect to the database,\n",
    "connection = engine.connect()\n",
    "\n",
    "# start time,\n",
    "start_time = time.time()\n",
    "\n",
    "df['OriginOID'] = df['OriginOID'].astype('int')\n",
    "df['DestinationOID'] = df['DestinationOID'].astype('int')\n",
    "df['DestinationRank'] = df['DestinationRank'].astype('int')\n",
    "df['Total_Time'] = df['Total_Time'].astype('Float64')\n",
    "df['Total_Distance'] = df['Total_Distance'].astype('Float64') \n",
    "\n",
    "#sort columns alphabetically and upload\n",
    "df = df[['OriginOID', 'DestinationOID', 'DestinationRank', 'Total_Time', 'Total_Distance']].sort_index(axis = 1)\n",
    "\n",
    "df.to_sql(con=con_str, name='census_tracts_centroids_od_results', schema='trucking_times',\n",
    "          if_exists='append', index=False, chunksize=10000)\n",
    "\n",
    "connection.close()\n",
    "log.info('All %s new records are inserted in %s seconds' % (len(df), time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
